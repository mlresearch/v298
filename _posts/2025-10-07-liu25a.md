---
title: Bidirectional Hierarchical Protein Multi-Modal Representation Learning
abstract: Protein representation learning is critical for numerous biological tasks.
  Recently, large transformer-based protein language models (pLMs) pretrained on large
  scale protein sequences have demonstrated significant success in sequence-based
  tasks. However, pLMs lack structural context, and adapting them to structure-dependent
  tasks like binding affinity prediction remains a challenge. Conversely, graph neural
  networks (GNNs) designed to leverage 3D structural information have shown promising
  generalization in protein-related prediction tasks, but their effectiveness is often
  constrained by the scarcity of labeled structural data. Recognizing that sequence
  and structural representations are complementary perspectives of the same protein
  entity, we propose a multimodal bidirectional hierarchical fusion framework to effectively
  merge these modalities. Our framework employs attention and gating mechanisms to
  enable effective interaction between pLMs-generated sequential representations and
  GNN-extracted structural features, improving information exchange and enhancement
  across layers of the neural network. This bidirectional and hierarchical (Bi-Hierarchical)
  fusion approach leverages the strengths of both modalities to capture richer and
  more comprehensive protein representations. Based on the framework, we further introduce
  local Bi-Hierarchical Fusion with gating and global Bi-Hierarchical Fusion with
  multihead self-attention approaches. Through extensive experiments on a diverse
  set of protein-related tasks, our method demonstrates consistent improvements over
  strong baselines and existing fusion techniques in a variety of protein representation
  learning benchmarks, including react (enzyme/EC classification), model quality assessment
  (MQA), protein-ligand binding affinity prediction (LBA), protein-protein binding
  site prediction (PPBS), and B cell epitopes prediction (BCEs). Our method establishes
  a new state-of-the-art for multimodal protein representation learning, emphasizing
  the efficacy of Bi-Hierarchical Fusion in bridging sequence and structural modalities.
booktitle: Machine Learning for Healthcare 2025
year: '2025'
url: https://openreview.net/forum?id=vnTFLI1DB4
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25a
month: 0
tex_title: Bidirectional Hierarchical Protein Multi-Modal Representation Learning
cycles: false
bibtex_author: Liu, Xuefeng and Jiang, Songhao and Tien, Chih-chan and Xu, Jinbo and
  Stevens, Rick L.
author:
- given: Xuefeng
  family: Liu
- given: Songhao
  family: Jiang
- given: Chih-chan
  family: Tien
- given: Jinbo
  family: Xu
- given: Rick L.
  family: Stevens
date: 2025-10-07
address:
container-title: Proceedings of the 10th Machine Learning for Healthcare Conference
volume: '298'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v298/main/assets/liu25a/liu25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
